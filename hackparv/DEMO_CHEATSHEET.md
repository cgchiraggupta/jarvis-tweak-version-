# ğŸ¬ DEMO CHEATSHEET - Quick Reference

**Print this or keep on second screen during demo!**

---

## ğŸš€ **START DEMO (Before Judges)**

```bash
# Terminal 1: Start servers
cd /Users/apple/hackparv
./start_assistant.sh

# Terminal 2: Prepare
cd /Users/apple/hackparv/self-operating-computer
source venv/bin/activate
clear

# Browser: Open UI
open /Users/apple/hackparv/jarvis/dashboard.html
```

**âœ… Verify**: `curl http://localhost:4001/health`

---

## ğŸ¯ **GUARANTEED COMMANDS (Won't Fail)**

```bash
# Use these in front of judges:

operate --model=assistant --prompt="open Finder"
operate --model=assistant --prompt="open Safari"
operate --model=assistant --prompt="open Notes"
operate --model=assistant --prompt="open Calendar"
operate --model=assistant --prompt="open Terminal"
operate --model=assistant --prompt="open Mail"
```

---

## ğŸª **DEMO SEQUENCE**

### **Option 1: Automated Demo**
```bash
./demo_for_judges.sh
```
**Runs perfect sequence automatically!**

### **Option 2: Manual Demo**
```bash
# 1. Show UI in browser
open jarvis/dashboard.html

# 2. Run commands
operate --model=assistant --prompt="open Finder"
operate --model=assistant --prompt="open Safari"

# 3. Let judge choose one
operate --model=assistant --prompt="[their choice]"
```

---

## ğŸ’¡ **WHAT TO SAY**

**Opening**: "I'll show you AI controlling a computer in real-time using vision."

**During**: "Watch - the AI is analyzing my screen right now... deciding what to do... executing!"

**After**: "That was GPT-4 Vision seeing my desktop and controlling it autonomously."

---

## ğŸ†˜ **IF SOMETHING FAILS**

### Restart servers:
```bash
Ctrl+C (in server terminal)
./start_assistant.sh
```

### Show backup:
```bash
cat TEST_RESULTS.md
open screenshots/screenshot.png
```

---

## ğŸ¤ **Q&A ANSWERS**

**"How does it work?"**
â†’ "Screenshots â†’ GPT-4 Vision â†’ JSON actions â†’ PyAutoGUI executes"

**"What can it do?"**
â†’ "Anything you can do: open apps, browse web, file management"

**"Is it safe?"**
â†’ "Yes - 10 iteration limit, human objectives only, Ctrl+C stops it"

**"Hardest part?"**
â†’ "Bridging Python + Node.js + GPT-4 Vision in real-time"

---

## ğŸ“Š **TECH SPECS**

- **Languages**: Python 3.13 + Node.js 16+
- **AI Model**: GPT-4 Vision (gpt-4o)
- **Control**: PyAutoGUI (macOS Accessibility API)
- **Vision**: Base64 screenshots â†’ OpenAI API
- **Response Time**: 5-10 seconds per action

---

## ğŸ **SHOW & TELL**

**Show this during demo:**
1. âœ… Dashboard UI (browser)
2. âœ… Terminal with commands
3. âœ… Apps actually opening
4. âœ… Screenshot (what AI sees)
5. âœ… Architecture diagram (ARCHITECTURE.md)

---

## âš¡ **TERMINAL COMMANDS**

```bash
# Increase font (readable from back)
Cmd + "+"

# Clear screen
clear

# Stop command
Ctrl + C

# Health check
curl http://localhost:4001/health
```

---

## ğŸ† **SUCCESS = JUDGES SEE:**

1. You type a command
2. AI analyzes screen
3. Actions execute (keyboard/mouse moves)
4. App opens
5. "Objective Complete!"

**They'll be impressed! ğŸ‰**

---

**KEEP CALM AND DEMO ON! ğŸš€**



